{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 943
        },
        "id": "stNE08sKToXB",
        "outputId": "1976797f-55b0-4138-e2c1-dcb930193f49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing [arraiz_2015] Psychometrics as a Tool to Improve Screening and Access to Credit\n",
            "  -> could not download directly: not-a-direct-pdf (text/html; charset=UTF-8). Marking for manual upload.\n",
            "Processing [alibhai_2023] Evening the Credit Score - World Bank\n",
            "  -> downloaded.\n",
            "Processing [fine_2024] Psychometric-Based Credit Scoring for Underbanked\n",
            "  -> could not download directly: not-a-direct-pdf (text/html). Marking for manual upload.\n",
            "Processing [bjorkegren_2018] Behavior Revealed in Mobile Phone Usage Predicts Loan Repayment\n",
            "  -> downloaded.\n",
            "Processing [mobile_usage] Mobile Phone Usage Data for Credit Scoring (working paper)\n",
            "  -> could not download directly: not-a-direct-pdf (text/html; charset=utf-8). Marking for manual upload.\n",
            "Processing [telecom_airtime_2024] Telecom Airtime Credit Risk Prediction\n",
            "  -> downloaded.\n",
            "Processing [socialcapital_cassar] The Effect of Social Capital on Group Loan Repayment (Cassar)\n",
            "  -> downloaded.\n",
            "Processing [rezaei_2021] The Structure of Borrower Social Network Matters (Rezaei)\n",
            "  -> could not download directly: not-a-direct-pdf (text/html; charset=UTF-8). Marking for manual upload.\n",
            "Processing [postelnicu_2019] External Social Ties and Loan Repayment (Postelnicu)\n",
            "  -> could not download directly: not-a-direct-pdf (text/html; charset=UTF-8). Marking for manual upload.\n",
            "Processing [zhu_2023] Explainable prediction of loan default (Zhu et al.)\n",
            "  -> could not download directly: not-a-direct-pdf (text/html;charset=UTF-8). Marking for manual upload.\n",
            "Processing [zhang_2025] Data-Driven Loan Default Prediction (Zhang et al.)\n",
            "  -> could not download directly: not-a-direct-pdf (text/html). Marking for manual upload.\n",
            "Processing [iitm_mfi_2022] Loan Default Prediction on Indian MFI Dataset (IITM thesis)\n",
            "  -> downloaded.\n",
            "\n",
            "Some PDFs could not be downloaded automatically. Please upload them now via Colab file upload widget.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f7f80259-86d4-4177-a888-84156fa05cd3\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-f7f80259-86d4-4177-a888-84156fa05cd3\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping extraction for arraiz_2015: no local file found\n",
            "Extracted text from alibhai_2023 (chars=14266)\n",
            "Skipping extraction for fine_2024: no local file found\n",
            "Extracted text from bjorkegren_2018 (chars=116572)\n",
            "Skipping extraction for mobile_usage: no local file found\n",
            "Extracted text from telecom_airtime_2024 (chars=38415)\n",
            "Extracted text from socialcapital_cassar (chars=54350)\n",
            "Skipping extraction for rezaei_2021: no local file found\n",
            "Skipping extraction for postelnicu_2019: no local file found\n",
            "Skipping extraction for zhu_2023: no local file found\n",
            "Skipping extraction for zhang_2025: no local file found\n",
            "Extracted text from iitm_mfi_2022 (chars=49635)\n",
            "Doc alibhai_2023 -> 7 chunks\n",
            "Doc bjorkegren_2018 -> 43 chunks\n",
            "Doc telecom_airtime_2024 -> 18 chunks\n",
            "Doc socialcapital_cassar -> 33 chunks\n",
            "Doc iitm_mfi_2022 -> 31 chunks\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Embedding batches: 100%|██████████| 3/3 [00:18<00:00,  6.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved metadata: data/metadata.jsonl\n",
            "Saved FAISS index: data/faiss_index.bin\n",
            "Saved retrieval report: data/retrieval_report.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os, io, json, math, re, hashlib\n",
        "from pathlib import Path\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import pdfplumber\n",
        "from tqdm import tqdm\n",
        "import requests\n",
        "import faiss\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "import numpy as np # Import numpy\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "DATA_DIR = Path(\"data\")\n",
        "PDF_DIR = DATA_DIR / \"documents\"\n",
        "PDF_DIR.mkdir(parents=True, exist_ok=True)\n",
        "META_FILE = DATA_DIR / \"metadata.jsonl\"\n",
        "INDEX_FILE = DATA_DIR / \"faiss_index.bin\"\n",
        "EMB_MODEL_NAME = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "\n",
        "# --- Configure your papers list here ---\n",
        "# For each item: either provide 'url' (direct link to PDF) OR set 'upload': True and\n",
        "# upload the PDF file when prompted in Colab.\n",
        "PAPERS = [\n",
        "    {\"id\":\"arraiz_2015\", \"title\":\"Psychometrics as a Tool to Improve Screening and Access to Credit\", \"url\":\"https://publications.iadb.org/publications/english/document/Psychometrics-as-a-Tool-to-Improve-Screening-and-Access-to-Credit.pdf\"},\n",
        "    {\"id\":\"alibhai_2023\", \"title\":\"Evening the Credit Score - World Bank\", \"url\":\"https://documents1.worldbank.org/curated/en/099440203162337439/pdf/IDU046d2582b04f4b047d6086a408f375dfc12ae.pdf\"},\n",
        "    {\"id\":\"fine_2024\", \"title\":\"Psychometric-Based Credit Scoring for Underbanked\", \"url\":\"https://www.mdpi.com/1911-8074/17/9/423\"},\n",
        "    {\"id\":\"bjorkegren_2018\", \"title\":\"Behavior Revealed in Mobile Phone Usage Predicts Loan Repayment\", \"url\":\"https://dan.bjorkegren.com/danbjork_grissen_creditscoring.pdf\"},\n",
        "    {\"id\":\"mobile_usage\", \"title\":\"Mobile Phone Usage Data for Credit Scoring (working paper)\", \"url\":\"https://arxiv.org/abs/1712.05840\"},\n",
        "    {\"id\":\"telecom_airtime_2024\", \"title\":\"Telecom Airtime Credit Risk Prediction\", \"url\":\"https://www.engineeringpaper.net/archives/2024/vol6issue2/PartA/6-2-4-193.pdf\"},\n",
        "    {\"id\":\"socialcapital_cassar\", \"title\":\"The Effect of Social Capital on Group Loan Repayment (Cassar)\", \"url\":\"https://www.findevgateway.org/sites/default/files/publications/files/mfg-en-paper-the-effect-of-social-capital-on-group-loan-repayment-evidence-from-artefactual-field-experiments-jun-2005.pdf\"},\n",
        "    {\"id\":\"rezaei_2021\", \"title\":\"The Structure of Borrower Social Network Matters (Rezaei)\", \"url\":\"https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4597857\"},\n",
        "    {\"id\":\"postelnicu_2019\", \"title\":\"External Social Ties and Loan Repayment (Postelnicu)\", \"url\":\"https://www.tandfonline.com/doi/full/10.1080/00220388.2018.1464148\"},\n",
        "    {\"id\":\"zhu_2023\", \"title\":\"Explainable prediction of loan default (Zhu et al.)\", \"url\":\"https://www.sciengine.com/doi/10.1016/j.dsm.2023.04.003\"},\n",
        "    {\"id\":\"zhang_2025\", \"title\":\"Data-Driven Loan Default Prediction (Zhang et al.)\", \"url\":\"https://www.mdpi.com/2079-8954/13/7/581\"},\n",
        "    {\"id\":\"iitm_mfi_2022\", \"title\":\"Loan Default Prediction on Indian MFI Dataset (IITM thesis)\", \"url\":\"https://eescholars.iitm.ac.in/sites/default/files/eethesis/ee17b035.pdf\"}\n",
        "]\n",
        "\n",
        "# Helper: download a url to file (if direct pdf)\n",
        "def download_pdf(url, save_path):\n",
        "    try:\n",
        "        r = requests.get(url, timeout=30, stream=True)\n",
        "        content_type = r.headers.get('content-type','')\n",
        "        if r.status_code == 200 and ('pdf' in content_type or url.lower().endswith('.pdf')):\n",
        "            with open(save_path, 'wb') as f:\n",
        "                for chunk in r.iter_content(1024*16):\n",
        "                    f.write(chunk)\n",
        "            return True, None\n",
        "        # handle html (some MDPI/journal pages require manual download or html->pdf)\n",
        "        return False, f\"not-a-direct-pdf ({content_type})\"\n",
        "    except Exception as e:\n",
        "        return False, str(e)\n",
        "\n",
        "# 1) Download / Ask for manual upload when required\n",
        "uploaded_files = {}\n",
        "for p in PAPERS:\n",
        "    pid = p['id']\n",
        "    out_path = PDF_DIR / f\"{pid}.pdf\"\n",
        "    print(f\"Processing [{pid}] {p['title']}\")\n",
        "    if 'url' in p and p['url']:\n",
        "        ok, err = download_pdf(p['url'], out_path)\n",
        "        if not ok:\n",
        "            print(f\"  -> could not download directly: {err}. Marking for manual upload.\")\n",
        "            p['needs_upload'] = True\n",
        "        else:\n",
        "            p['local_path'] = str(out_path)\n",
        "            print(\"  -> downloaded.\")\n",
        "    else:\n",
        "        p['needs_upload'] = True\n",
        "\n",
        "# If any need upload, prompt user (Colab files upload)\n",
        "to_upload = [p for p in PAPERS if p.get('needs_upload')]\n",
        "if to_upload:\n",
        "    print(\"\\nSome PDFs could not be downloaded automatically. Please upload them now via Colab file upload widget.\")\n",
        "    from google.colab import files\n",
        "    uploaded = files.upload()  # user selects files\n",
        "    for fn in uploaded.keys():\n",
        "        # map uploaded filename to a paper if names match, else just save\n",
        "        for p in to_upload:\n",
        "            expected = f\"{p['id']}.pdf\"\n",
        "            if fn == expected:\n",
        "                dst = PDF_DIR / expected\n",
        "                with open(dst,'wb') as f:\n",
        "                    f.write(uploaded[fn])\n",
        "                p['local_path'] = str(dst)\n",
        "                p.pop('needs_upload', None)\n",
        "                print(f\"Uploaded and mapped {fn} -> {p['id']}\")\n",
        "    # Any still unmapped remain flagged\n",
        "\n",
        "# 2) Extract text from PDFs\n",
        "def extract_text_from_pdf(path):\n",
        "    text = []\n",
        "    try:\n",
        "        with pdfplumber.open(path) as pdf:\n",
        "            for page in pdf.pages:\n",
        "                ptext = page.extract_text()\n",
        "                if ptext:\n",
        "                    # basic cleaning: remove excessive newlines\n",
        "                    ptext = re.sub(r'\\n{2,}', '\\n', ptext)\n",
        "                    text.append(ptext)\n",
        "    except Exception as e:\n",
        "        print(\"ERROR extracting\", path, e)\n",
        "    return \"\\n\".join(text)\n",
        "\n",
        "documents = []  # each doc: {'paper':..., 'text':..., 'path':...}\n",
        "for p in PAPERS:\n",
        "    lp = p.get('local_path')\n",
        "    if lp and os.path.exists(lp):\n",
        "        txt = extract_text_from_pdf(lp)\n",
        "        documents.append({\"id\": p['id'], \"title\": p['title'], \"path\": lp, \"text\": txt})\n",
        "        print(f\"Extracted text from {p['id']} (chars={len(txt)})\")\n",
        "    else:\n",
        "        print(f\"Skipping extraction for {p['id']}: no local file found\")\n",
        "\n",
        "# 3) Chunking (sentence-based, ~400 tokens target)\n",
        "def chunk_text(text, target_words=450, overlap_words=80):\n",
        "    # naive chunker using sentences\n",
        "    sents = sent_tokenize(text)\n",
        "    chunks = []\n",
        "    cur = []\n",
        "    cur_words = 0\n",
        "    for sent in sents:\n",
        "        wcount = len(word_tokenize(sent))\n",
        "        if cur_words + wcount > target_words and cur:\n",
        "            chunks.append(\" \".join(cur))\n",
        "            # overlap: keep last overlap_words worth of tokens as new base\n",
        "            if overlap_words > 0:\n",
        "                tail = \" \".join(word_tokenize(\" \".join(cur))[-overlap_words:])\n",
        "                cur = [tail]\n",
        "                cur_words = len(word_tokenize(tail))\n",
        "            else:\n",
        "                cur = []\n",
        "                cur_words = 0\n",
        "        cur.append(sent)\n",
        "        cur_words += wcount\n",
        "    if cur:\n",
        "        chunks.append(\" \".join(cur))\n",
        "    return chunks\n",
        "\n",
        "all_chunks = []\n",
        "for doc in documents:\n",
        "    chunks = chunk_text(doc['text'], target_words=450, overlap_words=90)\n",
        "    for i, c in enumerate(chunks):\n",
        "        chunk_id = hashlib.sha1((doc['id'] + \"_\" + str(i)).encode()).hexdigest()[:12]\n",
        "        meta = {\n",
        "            \"chunk_id\": chunk_id,\n",
        "            \"paper_id\": doc['id'],\n",
        "            \"paper_title\": doc['title'],\n",
        "            \"chunk_index\": i,\n",
        "            \"text\": c[:2000]  # keep up to 2k chars in memory export for metadata file; full text stored in files if desired\n",
        "        }\n",
        "        all_chunks.append(meta)\n",
        "    print(f\"Doc {doc['id']} -> {len(chunks)} chunks\")\n",
        "\n",
        "# 4) Embeddings\n",
        "model = SentenceTransformer(EMB_MODEL_NAME)\n",
        "batch_size = 64\n",
        "embeddings = []\n",
        "for i in tqdm(range(0, len(all_chunks), batch_size), desc=\"Embedding batches\"):\n",
        "    batch_texts = [c['text'] for c in all_chunks[i:i+batch_size]]\n",
        "    batch_emb = model.encode(batch_texts, show_progress_bar=False, convert_to_numpy=True)\n",
        "    embeddings.append(batch_emb)\n",
        "embeddings = np.vstack(embeddings)\n",
        "\n",
        "# 5) Build FAISS index & persist metadata\n",
        "dim = embeddings.shape[1]\n",
        "index = faiss.IndexFlatIP(dim)  # inner product (use cosine after normalization)\n",
        "# normalize vectors for cosine similarity\n",
        "faiss.normalize_L2(embeddings)\n",
        "index.add(embeddings)\n",
        "faiss.write_index(index, str(INDEX_FILE))\n",
        "\n",
        "# Write metadata.jsonl (full metadata per chunk)\n",
        "with open(META_FILE, \"w\", encoding=\"utf-8\") as mf:\n",
        "    for c in all_chunks:\n",
        "        json.dump(c, mf, ensure_ascii=False)\n",
        "        mf.write(\"\\n\")\n",
        "\n",
        "print(\"Saved metadata:\", META_FILE)\n",
        "print(\"Saved FAISS index:\", INDEX_FILE)\n",
        "\n",
        "# 6) Basic retrieval test (sample queries)\n",
        "sample_queries = [\n",
        "    \"Which mobile phone features predict default?\",\n",
        "    \"How psychometric tests predict repayment behavior\",\n",
        "    \"Group lending peer monitoring and repayment\"\n",
        "]\n",
        "from sentence_transformers import util\n",
        "retrieval_report = {}\n",
        "for q in sample_queries:\n",
        "    q_emb = model.encode(q, convert_to_numpy=True)\n",
        "    faiss.normalize_L2(q_emb.reshape(1,-1))\n",
        "    D, I = index.search(q_emb.reshape(1,-1), k=5)\n",
        "    hits = []\n",
        "    for idx in I[0]:\n",
        "        if idx < len(all_chunks):\n",
        "            hits.append({\n",
        "                \"paper_id\": all_chunks[idx]['paper_id'],\n",
        "                \"paper_title\": all_chunks[idx]['paper_title'],\n",
        "                \"chunk_index\": all_chunks[idx]['chunk_index'],\n",
        "                \"text_snippet\": all_chunks[idx]['text'][:500]\n",
        "            })\n",
        "    retrieval_report[q] = hits\n",
        "\n",
        "with open(DATA_DIR / \"retrieval_report.json\", \"w\", encoding=\"utf-8\") as rf:\n",
        "    json.dump(retrieval_report, rf, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(\"Saved retrieval report:\", DATA_DIR / \"retrieval_report.json\")\n",
        "# ---------- END PIPELINE ----------\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================\n",
        "# STEP B – Full Unconventional User Data Schema & Feature Engineering\n",
        "# SINGLE COLAB CELL VERSION (paste and run)\n",
        "# ==============================================================\n",
        "\n",
        "import json, math, random\n",
        "from datetime import datetime, timedelta\n",
        "from collections import Counter\n",
        "from pathlib import Path\n",
        "from typing import Dict, Any, List\n",
        "import statistics as stats\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 1. JSON SCHEMA (REFERENCE)\n",
        "# ---------------------------------------------------------------------\n",
        "\n",
        "SCHEMA = {\n",
        "    \"user_id\": \"string\",\n",
        "    \"timestamp\": \"ISO8601 datetime\",\n",
        "\n",
        "    \"demographics\": {\n",
        "        \"age\": \"int\",\n",
        "        \"gender\": \"string\",\n",
        "        \"marital_status\": \"string\",\n",
        "        \"education_level\": \"string\",\n",
        "        \"occupation\": \"string\",\n",
        "        \"monthly_income\": \"float\",\n",
        "        \"income_source_stability\": \"float 0-1\"\n",
        "    },\n",
        "\n",
        "    \"mobile_metadata\": {\n",
        "        \"avg_daily_calls\": \"float\",\n",
        "        \"avg_daily_sms\": \"float\",\n",
        "        \"unique_contacts_30d\": \"int\",\n",
        "        \"call_diversity_index\": \"float\",\n",
        "        \"night_activity_ratio\": \"float\",\n",
        "        \"airtime_topup_frequency\": \"float\",\n",
        "        \"avg_topup_amount\": \"float\",\n",
        "        \"data_usage_variance\": \"float\",\n",
        "        \"mobility_radius_km\": \"float\",\n",
        "        \"days_inactive_last_30\": \"int\"\n",
        "    },\n",
        "\n",
        "    \"psychometrics\": {\n",
        "        \"conscientiousness_score\": \"float\",\n",
        "        \"honesty_humility_score\": \"float\",\n",
        "        \"risk_aversion_score\": \"float\",\n",
        "        \"impulse_control_score\": \"float\",\n",
        "        \"numerical_ability_score\": \"float\",\n",
        "        \"business_aptitude_score\": \"float\",\n",
        "        \"confidence_bias_score\": \"float\"\n",
        "    },\n",
        "\n",
        "    \"financial_behavior\": {\n",
        "        \"savings_frequency\": \"float\",\n",
        "        \"savings_amount_variance\": \"float\",\n",
        "        \"bill_payment_timeliness\": \"float\",\n",
        "        \"wallet_balance_lows_last_90d\": \"int\",\n",
        "        \"credit_utilization_ratio\": \"float\",\n",
        "        \"purchase_spread_index\": \"float\"\n",
        "    },\n",
        "\n",
        "    \"social_network\": {\n",
        "        \"shg_membership\": \"bool\",\n",
        "        \"peer_monitoring_strength\": \"float\",\n",
        "        \"community_reputation_score\": \"float\",\n",
        "        \"dependents_in_household\": \"int\",\n",
        "        \"consistency_in_group_meetings\": \"float\"\n",
        "    },\n",
        "\n",
        "    \"loan_history\": {\n",
        "        \"previous_loans\": \"int\",\n",
        "        \"previous_defaults\": \"int\",\n",
        "        \"previous_late_payments\": \"int\",\n",
        "        \"avg_repayment_delay_days\": \"float\"\n",
        "    }\n",
        "}\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 2. UTILITY HELPERS\n",
        "# ---------------------------------------------------------------------\n",
        "\n",
        "def iso_now():\n",
        "    return datetime.utcnow().isoformat() + \"Z\"\n",
        "\n",
        "def validate_profile(profile: Dict[str, Any]):\n",
        "    \"\"\"Validate required fields + numeric ranges.\"\"\"\n",
        "    errors = []\n",
        "\n",
        "    required = [\n",
        "        \"user_id\", \"timestamp\", \"demographics\", \"mobile_metadata\",\n",
        "        \"psychometrics\", \"financial_behavior\", \"social_network\", \"loan_history\"\n",
        "    ]\n",
        "\n",
        "    for r in required:\n",
        "        if r not in profile:\n",
        "            errors.append(f\"Missing field: {r}\")\n",
        "\n",
        "    # demographic checks\n",
        "    if \"demographics\" in profile:\n",
        "        age = profile[\"demographics\"].get(\"age\")\n",
        "        if age is not None and not (18 <= age <= 100):\n",
        "            errors.append(\"Age must be 18–100.\")\n",
        "        income = profile[\"demographics\"].get(\"monthly_income\")\n",
        "        if income is not None and income < 0:\n",
        "            errors.append(\"Income must be >= 0.\")\n",
        "\n",
        "    # psychometric checks\n",
        "    if \"psychometrics\" in profile:\n",
        "        for k, v in profile[\"psychometrics\"].items():\n",
        "            if v is not None and not (0 <= v <= 1):\n",
        "                errors.append(f\"Psychometric {k} must be 0–1\")\n",
        "\n",
        "    return errors\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 3. MOBILE METADATA FEATURE ENGINEERING\n",
        "# ---------------------------------------------------------------------\n",
        "\n",
        "def shannon_diversity(counter):\n",
        "    total = sum(counter.values())\n",
        "    if total == 0:\n",
        "        return 0\n",
        "    entropy = 0\n",
        "    for c in counter.values():\n",
        "        p = c / total\n",
        "        entropy -= p * math.log(p + 1e-12)\n",
        "    max_entropy = math.log(len(counter)) if len(counter) else 1\n",
        "    return entropy / max_entropy if max_entropy else 0\n",
        "\n",
        "def compute_mobile_features(call_logs, sms_logs, topups, data_usage, as_of=None):\n",
        "    if as_of is None:\n",
        "        as_of = datetime.utcnow()\n",
        "\n",
        "    def last_n_days(dt, n):\n",
        "        return dt >= as_of - timedelta(days=n)\n",
        "\n",
        "    # Parse calls\n",
        "    calls = []\n",
        "    for c in call_logs:\n",
        "        try:\n",
        "            t = datetime.fromisoformat(c[\"timestamp\"].replace(\"Z\",\"\"))\n",
        "            calls.append({\"t\": t, \"contact\": c.get(\"contact_id\")})\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    sms = []\n",
        "    for s in sms_logs:\n",
        "        try:\n",
        "            t = datetime.fromisoformat(s[\"timestamp\"].replace(\"Z\",\"\"))\n",
        "            sms.append({\"t\": t, \"contact\": s.get(\"contact_id\")})\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    calls30 = [c for c in calls if last_n_days(c[\"t\"], 30)]\n",
        "    sms30   = [s for s in sms if last_n_days(s[\"t\"], 30)]\n",
        "\n",
        "    # core mobile features\n",
        "    avg_daily_calls = len(calls30) / 30\n",
        "    avg_daily_sms   = len(sms30) / 30\n",
        "\n",
        "    unique_contacts = len(\n",
        "        set(c[\"contact\"] for c in calls30 if c[\"contact\"]) |\n",
        "        set(s[\"contact\"] for s in sms30 if s[\"contact\"])\n",
        "    )\n",
        "\n",
        "    diversity = shannon_diversity(\n",
        "        Counter(c[\"contact\"] for c in calls30 if c[\"contact\"])\n",
        "    )\n",
        "\n",
        "    night_calls = [c for c in calls30 if 0 <= c[\"t\"].hour < 6]\n",
        "    night_ratio = len(night_calls) / len(calls30) if calls30 else 0\n",
        "\n",
        "    # topups\n",
        "    parsed_topups = []\n",
        "    for t in topups:\n",
        "        try:\n",
        "            dt = datetime.fromisoformat(t[\"timestamp\"].replace(\"Z\",\"\"))\n",
        "            parsed_topups.append({\"t\": dt, \"amount\": float(t.get(\"amount\",0))})\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    topups30 = [t for t in parsed_topups if last_n_days(t[\"t\"], 30)]\n",
        "\n",
        "    topup_freq = len(topups30) / 30\n",
        "    avg_topup_amount = (\n",
        "        sum(t[\"amount\"] for t in topups30) / len(topups30)\n",
        "        if topups30 else 0\n",
        "    )\n",
        "\n",
        "    # data usage variance\n",
        "    parsed_usage = []\n",
        "    for u in data_usage:\n",
        "        try:\n",
        "            dt = datetime.fromisoformat(u[\"date\"].replace(\"Z\",\"\"))\n",
        "            if last_n_days(dt, 30):\n",
        "                parsed_usage.append(u.get(\"mb_used\", 0))\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    data_var = stats.pvariance(parsed_usage) if len(parsed_usage) > 1 else 0\n",
        "\n",
        "    # inactivity\n",
        "    active_days = set(\n",
        "        [c[\"t\"].date() for c in calls30] +\n",
        "        [s[\"t\"].date() for s in sms30] +\n",
        "        [t[\"t\"].date() for t in topups30]\n",
        "    )\n",
        "    inactive_days = 30 - len(active_days)\n",
        "\n",
        "    return {\n",
        "        \"avg_daily_calls\": round(avg_daily_calls,4),\n",
        "        \"avg_daily_sms\": round(avg_daily_sms,4),\n",
        "        \"unique_contacts_30d\": unique_contacts,\n",
        "        \"call_diversity_index\": round(diversity,4),\n",
        "        \"night_activity_ratio\": round(night_ratio,4),\n",
        "        \"airtime_topup_frequency\": round(topup_freq,4),\n",
        "        \"avg_topup_amount\": round(avg_topup_amount,2),\n",
        "        \"data_usage_variance\": round(data_var,4),\n",
        "        \"mobility_radius_km\": 0.0,\n",
        "        \"days_inactive_last_30\": inactive_days\n",
        "    }\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 4. PSYCHOMETRIC SCORING\n",
        "# ---------------------------------------------------------------------\n",
        "\n",
        "def psychometric_scoring(responses: Dict[str, int]):\n",
        "    groups = {\n",
        "        \"conscientiousness\":   [k for k in responses if k.startswith(\"C_\")],\n",
        "        \"impulse_control\":     [k for k in responses if k.startswith(\"I_\")],\n",
        "        \"honesty_humility\":    [k for k in responses if k.startswith(\"H_\")],\n",
        "        \"risk_aversion\":       [k for k in responses if k.startswith(\"R_\")],\n",
        "        \"numerical_ability\":   [k for k in responses if k.startswith(\"N_\")],\n",
        "        \"business_aptitude\":   [k for k in responses if k.startswith(\"B_\")],\n",
        "        \"confidence_bias\":     [k for k in responses if k.startswith(\"CB_\")]\n",
        "    }\n",
        "\n",
        "    def scale(vals):\n",
        "        if not vals:\n",
        "            return None\n",
        "        return round((sum(vals)/len(vals) - 1) / 4, 4)\n",
        "\n",
        "    return {\n",
        "        \"conscientiousness_score\": scale([responses[k] for k in groups[\"conscientiousness\"]]),\n",
        "        \"honesty_humility_score\":  scale([responses[k] for k in groups[\"honesty_humility\"]]),\n",
        "        \"risk_aversion_score\":     scale([responses[k] for k in groups[\"risk_aversion\"]]),\n",
        "        \"impulse_control_score\":   scale([responses[k] for k in groups[\"impulse_control\"]]),\n",
        "        \"numerical_ability_score\": scale([responses[k] for k in groups[\"numerical_ability\"]]),\n",
        "        \"business_aptitude_score\": scale([responses[k] for k in groups[\"business_aptitude\"]]),\n",
        "        \"confidence_bias_score\":   scale([responses[k] for k in groups[\"confidence_bias\"]]),\n",
        "    }\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 5. FINANCIAL BEHAVIOR FEATURES\n",
        "# ---------------------------------------------------------------------\n",
        "\n",
        "def engineer_financial_behavior(savings_events, bill_payments, wallet_balance_ts):\n",
        "    now = datetime.utcnow()\n",
        "\n",
        "    sav_90 = [\n",
        "        s for s in savings_events\n",
        "        if datetime.fromisoformat(s[\"timestamp\"].replace(\"Z\",\"\")) >= now - timedelta(days=90)\n",
        "    ]\n",
        "    savings_freq = len(sav_90)/3\n",
        "    amounts = [s[\"amount\"] for s in sav_90]\n",
        "    savings_var = stats.pvariance(amounts) if len(amounts)>1 else 0\n",
        "\n",
        "    bills = [\n",
        "        b for b in bill_payments\n",
        "        if datetime.fromisoformat(b[\"timestamp\"].replace(\"Z\",\"\")) >= now - timedelta(days=365)\n",
        "    ]\n",
        "    on_time = sum(1 for b in bills if b.get(\"on_time\")) / len(bills) if bills else 0\n",
        "\n",
        "    lows = 0\n",
        "    for w in wallet_balance_ts:\n",
        "        dt = datetime.fromisoformat(w[\"date\"])\n",
        "        if dt >= now - timedelta(days=90) and w[\"balance\"] < 100:\n",
        "            lows += 1\n",
        "\n",
        "    return {\n",
        "        \"savings_frequency\": round(savings_freq,4),\n",
        "        \"savings_amount_variance\": round(savings_var,4),\n",
        "        \"bill_payment_timeliness\": round(on_time,4),\n",
        "        \"wallet_balance_lows_last_90d\": lows,\n",
        "        \"credit_utilization_ratio\": 0.0,\n",
        "        \"purchase_spread_index\": 0.0\n",
        "    }\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 6. ASSEMBLE FINAL PROFILE\n",
        "# ---------------------------------------------------------------------\n",
        "\n",
        "def assemble_profile(\n",
        "    user_id,\n",
        "    demographics,\n",
        "    call_logs,\n",
        "    sms_logs,\n",
        "    topups,\n",
        "    data_usage,\n",
        "    psych_responses,\n",
        "    savings_events,\n",
        "    bill_payments,\n",
        "    wallet_balance_ts,\n",
        "    social_info,\n",
        "    loan_history\n",
        "):\n",
        "    return {\n",
        "        \"user_id\": user_id,\n",
        "        \"timestamp\": iso_now(),\n",
        "        \"demographics\": demographics,\n",
        "        \"mobile_metadata\": compute_mobile_features(call_logs, sms_logs, topups, data_usage),\n",
        "        \"psychometrics\": psychometric_scoring(psych_responses),\n",
        "        \"financial_behavior\": engineer_financial_behavior(savings_events, bill_payments, wallet_balance_ts),\n",
        "        \"social_network\": social_info,\n",
        "        \"loan_history\": loan_history\n",
        "    }\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 7. SYNTHETIC TEST GENERATOR\n",
        "# ---------------------------------------------------------------------\n",
        "\n",
        "def rand_poisson(lam):\n",
        "    L = math.exp(-lam)\n",
        "    p = 1.0\n",
        "    k = 0\n",
        "    while p > L:\n",
        "        p *= random.random()\n",
        "        k += 1\n",
        "    return k - 1\n",
        "\n",
        "def generate_synthetic_profile():\n",
        "    now = datetime.utcnow()\n",
        "    calls, sms, topups, data_usage = [], [], [], []\n",
        "\n",
        "    for d in range(60):\n",
        "        day = now - timedelta(days=d)\n",
        "        data_usage.append({\"date\": day.date().isoformat(), \"mb_used\": max(0, random.gauss(50,20))})\n",
        "\n",
        "        # calls\n",
        "        for _ in range(rand_poisson(3)):\n",
        "            t = datetime(day.year, day.month, day.day, random.randint(0,23), random.randint(0,59))\n",
        "            calls.append({\"timestamp\": t.isoformat()+\"Z\", \"contact_id\": f\"c{random.randint(1,30)}\"})\n",
        "\n",
        "        # sms\n",
        "        for _ in range(max(0, int(random.gauss(1,1)))):\n",
        "            t = datetime(day.year, day.month, day.day, random.randint(0,23), random.randint(0,59))\n",
        "            sms.append({\"timestamp\": t.isoformat()+\"Z\", \"contact_id\": f\"c{random.randint(1,35)}\"})\n",
        "\n",
        "        # topups\n",
        "        if random.random() < 0.2:\n",
        "            t = datetime(day.year, day.month, day.day, 12, random.randint(0,59))\n",
        "            topups.append({\"timestamp\": t.isoformat()+\"Z\", \"amount\": round(random.gauss(50,20),2)})\n",
        "\n",
        "    psych = {\n",
        "        \"C_q1\":4,\"C_q2\":3,\"C_q3\":4,\n",
        "        \"I_q1\":3,\"I_q2\":2,\"I_q3\":3,\n",
        "        \"H_q1\":4,\"H_q2\":4,\n",
        "        \"R_q1\":2,\"R_q2\":3,\n",
        "        \"N_q1\":3,\"N_q2\":2,\n",
        "        \"B_q1\":3,\"B_q2\":3,\n",
        "        \"CB_q1\":4\n",
        "    }\n",
        "\n",
        "    savings_events = [\n",
        "        {\"timestamp\": (now-timedelta(days=random.randint(1,90))).isoformat()+\"Z\", \"amount\": random.randint(100,300)}\n",
        "        for _ in range(6)\n",
        "    ]\n",
        "\n",
        "    bill_payments = [\n",
        "        {\"timestamp\": (now-timedelta(days=random.randint(1,365))).isoformat()+\"Z\",\n",
        "         \"amount\": random.randint(300,600), \"on_time\": random.random()>0.2}\n",
        "        for _ in range(8)\n",
        "    ]\n",
        "\n",
        "    wallet = [\n",
        "        {\"date\": (now-timedelta(days=i)).date().isoformat(), \"balance\": max(0, random.gauss(500,250))}\n",
        "        for i in range(120)\n",
        "    ]\n",
        "\n",
        "    social = {\n",
        "        \"shg_membership\": True,\n",
        "        \"peer_monitoring_strength\": 0.7,\n",
        "        \"community_reputation_score\": 0.6,\n",
        "        \"dependents_in_household\": 3,\n",
        "        \"consistency_in_group_meetings\": 0.8\n",
        "    }\n",
        "\n",
        "    loan_history = {\n",
        "        \"previous_loans\":2,\n",
        "        \"previous_defaults\":0,\n",
        "        \"previous_late_payments\":1,\n",
        "        \"avg_repayment_delay_days\":3.5\n",
        "    }\n",
        "\n",
        "    return assemble_profile(\n",
        "        \"demo_user_001\",\n",
        "        demographics={\n",
        "            \"age\":34,\"gender\":\"female\",\"marital_status\":\"married\",\n",
        "            \"education_level\":\"secondary\",\"occupation\":\"vendor\",\n",
        "            \"monthly_income\":12000,\"income_source_stability\":0.6\n",
        "        },\n",
        "        call_logs=calls,\n",
        "        sms_logs=sms,\n",
        "        topups=topups,\n",
        "        data_usage=data_usage,\n",
        "        psych_responses=psych,\n",
        "        savings_events=savings_events,\n",
        "        bill_payments=bill_payments,\n",
        "        wallet_balance_ts=wallet,\n",
        "        social_info=social,\n",
        "        loan_history=loan_history\n",
        "    )\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 8. RUN DEMO\n",
        "# ---------------------------------------------------------------------\n",
        "\n",
        "demo_profile = generate_synthetic_profile()\n",
        "errors = validate_profile(demo_profile)\n",
        "\n",
        "print(\"Validation errors:\", errors)\n",
        "print(\"\\nSample Profile:\\n\")\n",
        "print(json.dumps(demo_profile, indent=2))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RifSNrK5WptN",
        "outputId": "b54c91e8-377d-4604-e874-3aadd091b930"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation errors: []\n",
            "\n",
            "Sample Profile:\n",
            "\n",
            "{\n",
            "  \"user_id\": \"demo_user_001\",\n",
            "  \"timestamp\": \"2025-11-14T12:51:17.675015Z\",\n",
            "  \"demographics\": {\n",
            "    \"age\": 34,\n",
            "    \"gender\": \"female\",\n",
            "    \"marital_status\": \"married\",\n",
            "    \"education_level\": \"secondary\",\n",
            "    \"occupation\": \"vendor\",\n",
            "    \"monthly_income\": 12000,\n",
            "    \"income_source_stability\": 0.6\n",
            "  },\n",
            "  \"mobile_metadata\": {\n",
            "    \"avg_daily_calls\": 3.0667,\n",
            "    \"avg_daily_sms\": 0.5333,\n",
            "    \"unique_contacts_30d\": 31,\n",
            "    \"call_diversity_index\": 0.9669,\n",
            "    \"night_activity_ratio\": 0.2283,\n",
            "    \"airtime_topup_frequency\": 0.1,\n",
            "    \"avg_topup_amount\": 54.04,\n",
            "    \"data_usage_variance\": 365.4078,\n",
            "    \"mobility_radius_km\": 0.0,\n",
            "    \"days_inactive_last_30\": 0\n",
            "  },\n",
            "  \"psychometrics\": {\n",
            "    \"conscientiousness_score\": 0.6667,\n",
            "    \"honesty_humility_score\": 0.75,\n",
            "    \"risk_aversion_score\": 0.375,\n",
            "    \"impulse_control_score\": 0.4167,\n",
            "    \"numerical_ability_score\": 0.375,\n",
            "    \"business_aptitude_score\": 0.5,\n",
            "    \"confidence_bias_score\": 0.75\n",
            "  },\n",
            "  \"financial_behavior\": {\n",
            "    \"savings_frequency\": 2.0,\n",
            "    \"savings_amount_variance\": 2751.6667,\n",
            "    \"bill_payment_timeliness\": 0.875,\n",
            "    \"wallet_balance_lows_last_90d\": 5,\n",
            "    \"credit_utilization_ratio\": 0.0,\n",
            "    \"purchase_spread_index\": 0.0\n",
            "  },\n",
            "  \"social_network\": {\n",
            "    \"shg_membership\": true,\n",
            "    \"peer_monitoring_strength\": 0.7,\n",
            "    \"community_reputation_score\": 0.6,\n",
            "    \"dependents_in_household\": 3,\n",
            "    \"consistency_in_group_meetings\": 0.8\n",
            "  },\n",
            "  \"loan_history\": {\n",
            "    \"previous_loans\": 2,\n",
            "    \"previous_defaults\": 0,\n",
            "    \"previous_late_payments\": 1,\n",
            "    \"avg_repayment_delay_days\": 3.5\n",
            "  }\n",
            "}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1437389079.py:333: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  now = datetime.utcnow()\n",
            "/tmp/ipython-input-1437389079.py:84: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().isoformat() + \"Z\"\n",
            "/tmp/ipython-input-1437389079.py:133: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  as_of = datetime.utcnow()\n",
            "/tmp/ipython-input-1437389079.py:259: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  now = datetime.utcnow()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================================================\n",
        "# SIMPLE RAG USING GROQ LLMs (NO ML MODEL)\n",
        "# ===============================================================\n",
        "\n",
        "!pip install -q groq sentence-transformers faiss-cpu\n",
        "\n",
        "import json\n",
        "import faiss\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from groq import Groq\n",
        "\n",
        "# ------------------------------\n",
        "# 1. Load Embedding Model\n",
        "# ------------------------------\n",
        "\n",
        "EMB_MODEL = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "embedder = SentenceTransformer(EMB_MODEL)\n",
        "\n",
        "# ------------------------------\n",
        "# 2. Load FAISS Index + Metadata\n",
        "# ------------------------------\n",
        "\n",
        "FAISS_PATH = \"data/faiss_index.bin\"\n",
        "META_PATH = \"data/metadata.jsonl\"\n",
        "\n",
        "index = faiss.read_index(FAISS_PATH)\n",
        "\n",
        "# load metadata (aligned with FAISS row order)\n",
        "metas = []\n",
        "with open(META_PATH, \"r\", encoding=\"utf-8\") as f:\n",
        "    for line in f:\n",
        "        metas.append(json.loads(line))\n",
        "\n",
        "# ------------------------------\n",
        "# 3. GROQ LLM Client\n",
        "# ------------------------------\n",
        "# Sign up at https://console.groq.com to get your free API key\n",
        "\n",
        "GROQ_API_KEY = \"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\"   # <-- put your key here\n",
        "client = Groq(api_key=GROQ_API_KEY)\n",
        "\n",
        "LLM_MODEL = \"llama-3.1-8b-instant\"     # Updated to a currently supported model\n",
        "\n",
        "\n",
        "# ------------------------------\n",
        "# 4. Function: Retrieve Top k Chunks\n",
        "# ------------------------------\n",
        "\n",
        "def retrieve_chunks(query, k=5):\n",
        "    q_emb = embedder.encode(query, convert_to_numpy=True)\n",
        "    q_emb = q_emb.reshape(1, -1).astype(np.float32)\n",
        "\n",
        "    # Normalize for cosine similarity\n",
        "    faiss.normalize_L2(q_emb)\n",
        "    D, I = index.search(q_emb, k)\n",
        "\n",
        "    results = []\n",
        "    for dist, idx in zip(D[0], I[0]):\n",
        "        if idx < len(metas):\n",
        "            m = metas[idx]\n",
        "            results.append({\n",
        "                \"score\": float(dist),\n",
        "                \"paper_id\": m[\"paper_id\"],\n",
        "                \"paper_title\": m[\"paper_title\"],\n",
        "                \"chunk_index\": m[\"chunk_index\"],\n",
        "                \"text_snippet\": m[\"text\"]   # limit length for prompt cleanliness\n",
        "            })\n",
        "    return results\n",
        "\n",
        "\n",
        "# ------------------------------\n",
        "# 5. Build RAG Prompt\n",
        "# ------------------------------\n",
        "\n",
        "def build_prompt(query, retrieved):\n",
        "    context = \"\"\n",
        "    for i, r in enumerate(retrieved, start=1):\n",
        "        context += f\"[CHUNK {i}] From: {r['paper_title']} — {r['text_snippet']}\\n\\n\"\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "You are an expert assistant that answers questions using ONLY the research context provided.\n",
        "\n",
        "User Query:\n",
        "{query}\n",
        "\n",
        "Relevant Research Chunks:\n",
        "{context}\n",
        "\n",
        "Instructions:\n",
        " - Use only the information in the chunks.\n",
        " - If the answer is not found in the chunks, say \"The research does not contain this information.\"\n",
        " - Cite chunk numbers like [CHUNK 1], [CHUNK 2].\n",
        " - Give a clear, concise answer.\n",
        "\n",
        "Answer:\n",
        "\"\"\"\n",
        "    return prompt\n",
        "\n",
        "\n",
        "# ------------------------------\n",
        "# 6. RAG Ask Function\n",
        "# ------------------------------\n",
        "\n",
        "def rag_answer(query, k=5):\n",
        "    retrieved = retrieve_chunks(query, k=k)\n",
        "    prompt = build_prompt(query, retrieved)\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=LLM_MODEL,\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        temperature=0.0,\n",
        "        max_tokens=600,\n",
        "    )\n",
        "\n",
        "    answer = response.choices[0].message.content\n",
        "    return {\n",
        "        \"query\": query,\n",
        "        \"answer\": answer,\n",
        "        \"retrieved_chunks\": retrieved\n",
        "    }\n",
        "\n",
        "\n",
        "# ------------------------------\n",
        "# 7. TEST IT\n",
        "# ------------------------------\n",
        "\n",
        "test_query = \"What psychometric traits are strongly linked to loan repayment behavior?\"\n",
        "result = rag_answer(test_query, k=5)\n",
        "\n",
        "print(\"USER QUERY:\", result[\"query\"])\n",
        "print(\"\\n--- ANSWER ---\\n\")\n",
        "print(result[\"answer\"])\n",
        "\n",
        "print(\"\\n--- CHUNKS USED ---\\n\")\n",
        "for c in result[\"retrieved_chunks\"]:\n",
        "    print(f\"- {c['paper_title']} (chunk {c['chunk_index']})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZKpvbKoaSvO",
        "outputId": "0206dd82-a594-4961-c4ba-034fa3fcd428"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "USER QUERY: What psychometric traits are strongly linked to loan repayment behavior?\n",
            "\n",
            "--- ANSWER ---\n",
            "\n",
            "Based on the provided research chunks, the psychometric traits strongly linked to loan repayment behavior are:\n",
            "\n",
            "- Business aptitude (as mentioned in [CHUNK 1])\n",
            "- Honesty (as mentioned in [CHUNK 1])\n",
            "- Periodicity of usage (as mentioned in [CHUNK 3])\n",
            "- Slope of usage (as mentioned in [CHUNK 3])\n",
            "- Correlations in usage (as mentioned in [CHUNK 3])\n",
            "- Variance (as mentioned in [CHUNK 3])\n",
            "- Personal trust between group members (as mentioned in [CHUNK 5])\n",
            "- Peer homogeneity (as mentioned in [CHUNK 5])\n",
            "\n",
            "These traits are linked to loan repayment behavior through various studies and experiments, including psychometric assessments, mobile phone usage analysis, and social capital research.\n",
            "\n",
            "--- CHUNKS USED ---\n",
            "\n",
            "- Evening the Credit Score - World Bank (chunk 2)\n",
            "- Behavior Revealed in Mobile Phone Usage Predicts Loan Repayment (chunk 13)\n",
            "- Behavior Revealed in Mobile Phone Usage Predicts Loan Repayment (chunk 15)\n",
            "- The Effect of Social Capital on Group Loan Repayment (Cassar) (chunk 22)\n",
            "- The Effect of Social Capital on Group Loan Repayment (Cassar) (chunk 0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------\n",
        "# SIMPLE RAG Q&A + MEMORY (Groq) - Single Colab Cell\n",
        "# Paste & run in Colab\n",
        "# ---------------------------\n",
        "\n",
        "!pip install -q groq sentence-transformers faiss-cpu\n",
        "\n",
        "import json, os, math, pathlib\n",
        "from typing import List, Dict, Any\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "import faiss\n",
        "from groq import Groq\n",
        "from datetime import datetime, UTC # Import UTC\n",
        "\n",
        "# ---------- CONFIG ----------\n",
        "GROQ_API_KEY = \"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\"   # <-- set your Groq key\n",
        "LLM_MODEL = \"llama-3.1-8b-instant\"     # change if you prefer other Groq model\n",
        "EMB_MODEL = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "FAISS_PATH = \"data/faiss_index.bin\"      # path to your FAISS index from ingestion\n",
        "META_PATH = \"data/metadata.jsonl\"        # metadata lines aligned with index\n",
        "MEMORY_PATH = \"data/memory.json\"         # simple local memory store\n",
        "\n",
        "# ---------- INIT CLIENTS ----------\n",
        "client = Groq(api_key=GROQ_API_KEY)\n",
        "embedder = SentenceTransformer(EMB_MODEL)\n",
        "\n",
        "# Load FAISS index + metadata\n",
        "if not os.path.exists(FAISS_PATH) or not os.path.exists(META_PATH):\n",
        "    raise FileNotFoundError(\"FAISS index or metadata.jsonl not found. Run ingestion first or change FAISS_PATH/META_PATH.\")\n",
        "\n",
        "index = faiss.read_index(FAISS_PATH)\n",
        "metas = [json.loads(line) for line in open(META_PATH, \"r\", encoding=\"utf-8\")]\n",
        "\n",
        "# ---------- MEMORY HELPERS ----------\n",
        "def load_memory() -> Dict[str, Any]:\n",
        "    if not os.path.exists(MEMORY_PATH):\n",
        "        return {}\n",
        "    return json.load(open(MEMORY_PATH, \"r\", encoding=\"utf-8\"))\n",
        "\n",
        "def save_memory(mem: Dict[str, Any]):\n",
        "    os.makedirs(os.path.dirname(MEMORY_PATH) or \".\", exist_ok=True)\n",
        "    json.dump(mem, open(MEMORY_PATH, \"w\", encoding=\"utf-8\"), indent=2)\n",
        "\n",
        "def add_to_memory(user_id: str, profile: Dict[str, Any]=None, utterance: Dict[str,Any]=None):\n",
        "    mem = load_memory()\n",
        "    if user_id not in mem:\n",
        "        mem[user_id] = {\"profile\": None, \"conversations\": []}\n",
        "    if profile:\n",
        "        mem[user_id][\"profile\"] = profile\n",
        "    if utterance:\n",
        "        mem[user_id][\"conversations\"].append(utterance)\n",
        "    save_memory(mem)\n",
        "\n",
        "# ---------- RETRIEVER ----------\n",
        "def retrieve_chunks(query: str, k: int=6) -> List[Dict[str,Any]]:\n",
        "    q_emb = embedder.encode(query, convert_to_numpy=True).astype(np.float32)\n",
        "    q_emb = q_emb.reshape(1, -1)\n",
        "    faiss.normalize_L2(q_emb)\n",
        "    D, I = index.search(q_emb, k)\n",
        "    results = []\n",
        "    for dist, idx in zip(D[0], I[0]):\n",
        "        if idx < len(metas):\n",
        "            m = metas[idx]\n",
        "            results.append({\n",
        "                \"score\": float(dist),\n",
        "                \"chunk_text\": m.get(\"text\",\"\")[:1000],\n",
        "                # keep metadata but do NOT surface titles to user later\n",
        "                \"paper_id\": m.get(\"paper_id\"),\n",
        "                \"paper_title\": m.get(\"paper_title\"),\n",
        "                \"chunk_index\": m.get(\"chunk_index\")\n",
        "            })\n",
        "    return results\n",
        "\n",
        "# ---------- PROMPT BUILDERS (internal, DO NOT INCLUDE CITATIONS IN USER ANSWER) ----------\n",
        "def profile_summary_for_prompt(profile: Dict[str,Any]) -> str:\n",
        "    # create a short structured summary that the LLM can use to reason\n",
        "    dem = profile.get(\"demographics\", {})\n",
        "    mob = profile.get(\"mobile_metadata\", {})\n",
        "    psych = profile.get(\"psychometrics\", {})\n",
        "    fin = profile.get(\"financial_behavior\", {})\n",
        "    soc = profile.get(\"social_network\", {})\n",
        "    loan = profile.get(\"loan_history\", {})\n",
        "    parts = []\n",
        "    parts.append(f\"Age: {dem.get('age','unknown')}, Occupation: {dem.get('occupation','unknown')}, Monthly income: {dem.get('monthly_income','unknown')}\")\n",
        "    parts.append(f\"Mobile: avg_calls={mob.get('avg_daily_calls','?')}, unique_contacts_30d={mob.get('unique_contacts_30d','?')}, days_inactive_30d={mob.get('days_inactive_last_30','?')}\")\n",
        "    parts.append(f\"Psychometrics (0-1): conscientious={psych.get('conscientiousness_score','?')}, impulse_control={psych.get('impulse_control_score','?')}, honesty={psych.get('honesty_humility_score','?')}\")\n",
        "    parts.append(f\"Financial behaviour: savings_freq={fin.get('savings_frequency','?')}, on_time_bill_frac={fin.get('bill_payment_timeliness','?')}, wallet_lows_90d={fin.get('wallet_balance_lows_last_90d','?')}\")\n",
        "    parts.append(f\"Social: shg_membership={soc.get('shg_membership',False)}, peer_monitoring={soc.get('peer_monitoring_strength','?')}\")\n",
        "    parts.append(f\"Loan history: prev_loans={loan.get('previous_loans',0)}, prev_defaults={loan.get('previous_defaults',0)}, prev_late={loan.get('previous_late_payments',0)}\")\n",
        "    return \"\\n\".join(parts)\n",
        "\n",
        "def build_internal_prompt(user_query: str, profile: Dict[str,Any], retrieved_chunks: List[Dict[str,Any]]) -> str:\n",
        "    # This prompt instructs the LLM to use the chunks to form an answer but not to reveal sources.\n",
        "    profile_summary = profile_summary_for_prompt(profile) if profile else \"No profile provided.\"\n",
        "    chunks_text = \"\\n\\n\".join([f\"CHUNK {i+1}: {c['chunk_text']}\" for i,c in enumerate(retrieved_chunks)])\n",
        "    prompt = f\"\"\"\n",
        "You are an expert microfinance advisor. You will be given:\n",
        "1) A short borrower profile summary (structured).\n",
        "2) A user question.\n",
        "3) A set of research text CHUNKs (raw excerpts). Use the CHUNKs strictly to ground your reasoning.\n",
        "\n",
        "Instructions:\n",
        "- Produce a single JSON object (no extra commentary) with exactly these top-level keys:\n",
        "  - \"eligibility\": one of [\"eligible\",\"maybe\",\"not_eligible\"]\n",
        "  - \"score\": float between 0.0 and 1.0 indicating likelihood of default (higher = higher risk). (If you reason the probability of default is p, set score=p.)\n",
        "  - \"verdict_text\": a 2-3 sentence plain-language verdict for the user (DO NOT mention or cite article titles or chunk ids).\n",
        "  - \"strong_points\": list of 3 short bullet strings (why the user is likely to be creditworthy)\n",
        "  - \"weak_points\": list of 3 short bullet strings (risks / reasons for concern)\n",
        "  - \"required_unconventional_data\": list of fields (from the checklist) that are MISSING from the profile and needed to improve the assessment\n",
        "  - \"actionable_recommendations\": list of 4 concrete, prioritized actions the borrower can take to improve eligibility (very specific)\n",
        "  - \"confidence\": one of [\"high\",\"medium\",\"low\"] indicating how confident you are based on available data\n",
        "  - \"raw_internal_reasoning\": one short paragraph that says which CHUNK features informed the decision (this is for audit; keep it generic, do not list paper titles)\n",
        "- Use only the CHUNK text and profile to decide. Do not invent facts outside them.\n",
        "- Do NOT include paper titles, DO NOT output CHUNK ids in the user-facing fields; you may reference CHUNKs only inside \"raw_internal_reasoning\".\n",
        "- If the profile lacks important unconventional fields, include them in \"required_unconventional_data\". The recommended required unconventional fields (use these labels):\n",
        "  [\"mobile_call_logs_30d\",\"airtime_topups_30d\",\"psychometric_responses\",\"savings_history_90d\",\"wallet_balance_timeseries_90d\",\"shg_membership_info\",\"transaction_history_180d\",\"sms_patterns_30d\"]\n",
        "- If you cannot answer because no relevant CHUNK supports the query, set \"verdict_text\" to \"The research does not contain this information.\", set \"eligibility\" to \"maybe\", score to 0.5 and confidence to \"low\".\n",
        "- Keep lists short and precise. Prioritize clarity for non-technical users.\n",
        "\n",
        "Now, here is the input:\n",
        "Profile summary:\n",
        "{profile_summary}\n",
        "\n",
        "User question:\n",
        "{user_query}\n",
        "\n",
        "CHUNKS:\n",
        "{chunks_text}\n",
        "\n",
        "Return ONLY the JSON object.\n",
        "\"\"\"\n",
        "    return prompt\n",
        "\n",
        "# ---------- MAIN RAG Q&A (structured) ----------\n",
        "def rag_qna_structured(user_query: str, user_id: str=None, profile: Dict[str,Any]=None, k:int=6) -> Dict[str,Any]:\n",
        "    \"\"\"\n",
        "    user_query: user's natural question (e.g., \"Am I eligible for a loan of 50k?\")\n",
        "    user_id: optional id for memory\n",
        "    profile: optional profile dict (if None, function will check memory for user_id)\n",
        "    returns: structured dict per prompt instructions\n",
        "    \"\"\"\n",
        "    # load profile from memory if not provided\n",
        "    if profile is None and user_id:\n",
        "        mem = load_memory()\n",
        "        profile = mem.get(user_id, {}).get(\"profile\")\n",
        "\n",
        "    # retrieve\n",
        "    # create a retrieval query that mixes user question & profile \"weak\" markers for better retrieval\n",
        "    retrieval_query = user_query\n",
        "    if profile:\n",
        "        # include top signals to help retrieval\n",
        "        try:\n",
        "            p_summary = profile_summary_for_prompt(profile)\n",
        "            retrieval_query = user_query + \" | profile summary: \" + \" \".join(p_summary.splitlines())\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    retrieved = retrieve_chunks(retrieval_query, k=k)\n",
        "\n",
        "    # Build prompt for Groq\n",
        "    prompt = build_internal_prompt(user_query, profile if profile else {}, retrieved)\n",
        "\n",
        "    # Call Groq LLM\n",
        "    resp = client.chat.completions.create(\n",
        "        model=LLM_MODEL,\n",
        "        messages=[{\"role\":\"user\",\"content\":prompt}],\n",
        "        temperature=0.0,\n",
        "        max_tokens=700\n",
        "    )\n",
        "\n",
        "    llm_text = resp.choices[0].message.content # Changed from resp.choices[0].message[\"content\"]\n",
        "\n",
        "    # Parse JSON out of the response robustly\n",
        "    try:\n",
        "        parsed = json.loads(llm_text.strip())\n",
        "    except Exception as e:\n",
        "        # fallback: try to extract first JSON-looking substring\n",
        "        import re\n",
        "        m = re.search(r'(\\{.*\\})', llm_text, flags=re.S)\n",
        "        if m:\n",
        "            parsed = json.loads(m.group(1))\n",
        "        else:\n",
        "            # return an error-structured object\n",
        "            parsed = {\n",
        "                \"eligibility\":\"maybe\",\n",
        "                \"score\":0.5,\n",
        "                \"verdict_text\":\"Could not parse model output. Please try again.\",\n",
        "                \"strong_points\":[],\n",
        "                \"weak_points\":[],\n",
        "                \"required_unconventional_data\":[\"mobile_call_logs_30d\",\"psychometric_responses\"],\n",
        "                \"actionable_recommendations\":[],\n",
        "                \"confidence\":\"low\",\n",
        "                \"raw_internal_reasoning\": llm_text[:800]\n",
        "            }\n",
        "\n",
        "    # Append conversation to memory for user\n",
        "    if user_id:\n",
        "        add_to_memory(user_id, profile=profile, utterance={\n",
        "            \"timestamp\": datetime.now(UTC).isoformat(), # Updated to use datetime.now(UTC)\n",
        "            \"query\": user_query,\n",
        "            \"response\": parsed\n",
        "        })\n",
        "\n",
        "    # Package additional debug info (retrieved chunk summaries) but DO NOT show these to final user unless needed\n",
        "    parsed[\"_debug\"] = {\n",
        "        \"retrieved_count\": len(retrieved),\n",
        "        \"retrieved_sample\": [ {\"text_snippet\": r[\"chunk_text\"][:300]} for r in retrieved ]\n",
        "    }\n",
        "    return parsed\n",
        "\n",
        "# ---------- USAGE EXAMPLE ----------\n",
        "if __name__ == \"__main__\":\n",
        "    # demo: load example profile if exists\n",
        "    demo_profile_path = \"/mnt/data/user_profile_example.json\"\n",
        "    demo_profile = None\n",
        "    if os.path.exists(demo_profile_path):\n",
        "        demo_profile = json.load(open(demo_profile_path,\"r\",encoding=\"utf-8\"))\n",
        "        print(\"Loaded demo profile from\", demo_profile_path)\n",
        "\n",
        "    # Example query\n",
        "    q = \"Am I likely to be able to get a small business loan of 50,000 INR? What are my strengths and weaknesses?\"\n",
        "    out = rag_qna_structured(q, user_id=\"demo_user_001\", profile=demo_profile, k=6)\n",
        "    print(\"\\n--- STRUCTURED OUTPUT ---\\n\")\n",
        "    print(json.dumps(out, indent=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UIs1vaafcdkD",
        "outputId": "5eb4cc5b-7e0b-4a9d-e3fd-9f4366d0fee1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- STRUCTURED OUTPUT ---\n",
            "\n",
            "{\n",
            "  \"eligibility\": \"maybe\",\n",
            "  \"score\": 0.5,\n",
            "  \"verdict_text\": \"The research does not contain this information.\",\n",
            "  \"strong_points\": [],\n",
            "  \"weak_points\": [],\n",
            "  \"required_unconventional_data\": [\n",
            "    \"mobile_call_logs_30d\",\n",
            "    \"airtime_topups_30d\",\n",
            "    \"psychometric_responses\",\n",
            "    \"savings_history_90d\",\n",
            "    \"wallet_balance_timeseries_90d\",\n",
            "    \"shg_membership_info\",\n",
            "    \"transaction_history_180d\",\n",
            "    \"sms_patterns_30d\"\n",
            "  ],\n",
            "  \"actionable_recommendations\": [\n",
            "    \"Provide psychometric responses to assess business aptitude and honesty.\",\n",
            "    \"Share mobile call logs and airtime top-ups for the last 30 days.\",\n",
            "    \"Offer savings history for the last 90 days.\",\n",
            "    \"Share wallet balance timeseries for the last 90 days.\"\n",
            "  ],\n",
            "  \"confidence\": \"low\",\n",
            "  \"raw_internal_reasoning\": \"The decision was based on the lack of relevant information in the provided CHUNKs and profile. The CHUNKs discuss psychometric credit scoring, its benefits, and its use in lending to women entrepreneurs, but do not provide specific information about the borrower's creditworthiness or eligibility for a loan.\",\n",
            "  \"_debug\": {\n",
            "    \"retrieved_count\": 6,\n",
            "    \"retrieved_sample\": [\n",
            "      {\n",
            "        \"text_snippet\": \"is no evidence access to formal finance for previously unbanked that access to psychometric-appraised loans kept borrowers unprofitable or \\u201c zombie \\u201d firms alive during the challenging Women entrepreneurs who were treated with the offer macroeconomic circumstances . However , treated firms of an unc\"\n",
            "      },\n",
            "      {\n",
            "        \"text_snippet\": \"March 2023\\nEVENING THE CREDIT SCORE: CAN PSYCHOMETRIC\\nCREDIT-SCORING ADDRESS COLLATERAL\\nABOUT THIS STUDY\\nCONSTRAINTS FOR WOMEN ENTREPRENEURS? This impact evaluation was\\nconducted by the World Bank\\u2019s Africa\\nAuthors: Salman Alibhai, Rachel Cassidy, Menaal Ebrahim, Markus Goldstein,\\nRegion Gender Innov\"\n",
            "      },\n",
            "      {\n",
            "        \"text_snippet\": \"closing in Ethiopia \\u2019 s Women Entrepreneurship the control group , to 17 % of firms closing in the treatment group . Impacts Development Project ( WEDP ) ; the Ethiopian microfinance institution of the psychometric-appraised loans on firm sales and profit growth were Wasasa ; and the Gender Innovati\"\n",
            "      },\n",
            "      {\n",
            "        \"text_snippet\": \"Hence , WHAT WE DID the standard due diligence was still a binding step of the The MFI used the psychometric credit scoring technology screening procedure . to offer large , uncollateralized loans of up to 250,000 Ethiopian birr ( US $ 7,500 ) to women entrepreneurs . The To evaluate the impact of u\"\n",
            "      },\n",
            "      {\n",
            "        \"text_snippet\": \"is an innovative technology \\u201c WEDP One Stop Shop \\u201d offices , in the cities of Adama designed to predict credit risk . Psychometrics\\u2014literally and Asela in the Oromia region . Women entrepreneurs \\u201c measurement of the mind \\u201d \\u2014uses questions designed who wanted a loan , but lacked collateral , were inv\"\n",
            "      },\n",
            "      {\n",
            "        \"text_snippet\": \"1 ) : S67\\u2013S76 . with 50-50 probability to receive an uncollateralized borrow formally ( from 42 percent to 89 percent ) and 12 loan or not . All women were informed of their random percent less likely to borrow informally ( from family and assignment . The treatment group received their loan friends\"\n",
            "      }\n",
            "    ]\n",
            "  }\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------\n",
        "# COLAB CELL: Interactive data collection + run RAG decision\n",
        "# ---------------------------\n",
        "# Paste this AFTER your previous cells that define:\n",
        "# - load_memory, save_memory, add_to_memory\n",
        "# - rag_qna_structured\n",
        "# - (FAISS, embedder, Groq client etc.)\n",
        "#\n",
        "# This cell will collect unconventional data fields (or NA), build a profile\n",
        "# in your schema, save to memory, call rag_qna_structured, and save/print output.\n",
        "# ---------------------------\n",
        "\n",
        "import json, os\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "\n",
        "# REQUIRED UNCONVENTIONAL FIELDS (labels used in prompts and by the RAG prompt)\n",
        "REQUIRED_UNCONVENTIONAL_FIELDS = [\n",
        "    \"mobile_call_logs_30d\",        # expects list of call dicts or 'NA'\n",
        "    \"airtime_topups_30d\",          # expects list of topup dicts or 'NA'\n",
        "    \"psychometric_responses\",      # expects dict of Q->Likert or 'NA'\n",
        "    \"savings_history_90d\",         # expects list of savings events or 'NA'\n",
        "    \"wallet_balance_timeseries_90d\", # expects list of daily balances or 'NA'\n",
        "    \"shg_membership_info\",         # expects dict {member:bool,peer_monitoring:float} or 'NA'\n",
        "    \"transaction_history_180d\",    # expects list of transaction dicts or 'NA'\n",
        "    \"sms_patterns_30d\"             # expects list of sms dicts or 'NA'\n",
        "]\n",
        "\n",
        "OUT_DIR = Path(\"data\")\n",
        "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def _prompt_list_of_dicts(field_name):\n",
        "    print(f\"\\nEnter {field_name} as JSON array of objects, or type NA (without quotes) if unavailable.\")\n",
        "    print(\"Examples:\")\n",
        "    if field_name == \"mobile_call_logs_30d\":\n",
        "        print('[{\"timestamp\":\"2025-11-01T08:12:00Z\",\"duration_sec\":120,\"contact_id\":\"c1\",\"direction\":\"out\"}, ...]')\n",
        "    elif field_name == \"airtime_topups_30d\":\n",
        "        print('[{\"timestamp\":\"2025-11-05T12:00:00Z\",\"amount\":50.0}, ...]')\n",
        "    elif field_name == \"savings_history_90d\":\n",
        "        print('[{\"timestamp\":\"2025-09-10T00:00:00Z\",\"amount\":200.0}, ...]')\n",
        "    elif field_name == \"wallet_balance_timeseries_90d\":\n",
        "        print('[{\"date\":\"2025-08-01\",\"balance\":450.0}, ...]')\n",
        "    elif field_name == \"transaction_history_180d\":\n",
        "        print('[{\"timestamp\":\"2025-06-01T10:00:00Z\",\"amount\":250.0,\"type\":\"sale\"}, ...]')\n",
        "    elif field_name == \"sms_patterns_30d\":\n",
        "        print('[{\"timestamp\":\"2025-11-01T09:00:00Z\",\"contact_id\":\"c1\",\"text_snippet\":\"paid today\"}, ...]')\n",
        "    raw = input(f\"{field_name} > \").strip()\n",
        "    if raw.upper() == \"NA\" or raw == \"\":\n",
        "        return \"NA\"\n",
        "    try:\n",
        "        parsed = json.loads(raw)\n",
        "        if not isinstance(parsed, list):\n",
        "            print(\"Expected a JSON array (list). Storing as single-element list.\")\n",
        "            parsed = [parsed]\n",
        "        return parsed\n",
        "    except Exception as e:\n",
        "        print(\"Could not parse JSON — saving as NA. Error:\", e)\n",
        "        return \"NA\"\n",
        "\n",
        "def _prompt_dict(field_name):\n",
        "    print(f\"\\nEnter {field_name} as JSON object (e.g., psychometric responses), or NA if unavailable.\")\n",
        "    if field_name == \"psychometric_responses\":\n",
        "        print('{\"C_q1\":4,\"C_q2\":3,\"C_q3\":4,\"I_q1\":3,\"I_q2\":2}')\n",
        "    if field_name == \"shg_membership_info\":\n",
        "        print('{\"shg_membership\": true, \"peer_monitoring_strength\": 0.7, \"consistency_in_group_meetings\": 0.8}')\n",
        "    raw = input(f\"{field_name} > \").strip()\n",
        "    if raw.upper() == \"NA\" or raw == \"\":\n",
        "        return \"NA\"\n",
        "    try:\n",
        "        parsed = json.loads(raw)\n",
        "        if not isinstance(parsed, dict):\n",
        "            print(\"Expected a JSON object — storing as NA.\")\n",
        "            return \"NA\"\n",
        "        return parsed\n",
        "    except Exception as e:\n",
        "        print(\"Could not parse JSON — saving as NA. Error:\", e)\n",
        "        return \"NA\"\n",
        "\n",
        "def collect_unconventional_inputs_interactive():\n",
        "    \"\"\"\n",
        "    Interactive console-based collector for the unconventional fields.\n",
        "    Returns a dict mapping field -> value ('NA' or parsed value).\n",
        "    \"\"\"\n",
        "    print(\"COLLECTING UNCONVENTIONAL DATA — type NA if not available.\\n(You can paste JSON arrays/objects directly when prompted.)\")\n",
        "    collected = {}\n",
        "    for f in REQUIRED_UNCONVENTIONAL_FIELDS:\n",
        "        if f in [\"psychometric_responses\", \"shg_membership_info\"]:\n",
        "            collected[f] = _prompt_dict(f)\n",
        "        else:\n",
        "            collected[f] = _prompt_list_of_dicts(f)\n",
        "    return collected\n",
        "\n",
        "# Build the profile structure expected by Step-B (minimum fields + unconventional parts)\n",
        "def build_profile_from_inputs(user_id: str, demographics: dict, unconventional_inputs: dict):\n",
        "    \"\"\"\n",
        "    demographics : minimal dict (age, occupation, monthly_income etc.) or {}\n",
        "    unconventional_inputs : from collector\n",
        "    Returns full profile dict compatible with your Step-B schema but may place 'NA' where missing.\n",
        "    \"\"\"\n",
        "    # Minimal structure: fill what we can; map unconventional inputs into schema fields used by pipeline\n",
        "    profile = {\n",
        "        \"user_id\": user_id,\n",
        "        \"timestamp\": datetime.utcnow().isoformat() + \"Z\",\n",
        "        \"demographics\": demographics or {},\n",
        "        # mobile_metadata will be computed if raw call/sms/topup data available; otherwise mark NA\n",
        "        \"mobile_metadata\": {},\n",
        "        \"psychometrics\": {},\n",
        "        \"financial_behavior\": {},\n",
        "        \"social_network\": {},\n",
        "        \"loan_history\": {}  # keep empty — you can extend to prompt loan history too\n",
        "    }\n",
        "\n",
        "    # Map mobile_call_logs_30d / sms_patterns_30d / airtime_topups_30d -> raw buckets (keep raw for reproducibility)\n",
        "    profile[\"_raw_unconventional\"] = unconventional_inputs  # store raw inputs for audits\n",
        "\n",
        "    # If available, perform minimal aggregation so RAG prompt has summary fields\n",
        "    # avg_daily_calls, unique_contacts_30d, days_inactive_last_30, airtime_topup_frequency, avg_topup_amount, data_usage_variance\n",
        "    try:\n",
        "        calls = unconventional_inputs.get(\"mobile_call_logs_30d\")\n",
        "        sms = unconventional_inputs.get(\"sms_patterns_30d\")\n",
        "        topups = unconventional_inputs.get(\"airtime_topups_30d\")\n",
        "        wallet_ts = unconventional_inputs.get(\"wallet_balance_timeseries_90d\")\n",
        "        savings = unconventional_inputs.get(\"savings_history_90d\")\n",
        "        psych = unconventional_inputs.get(\"psychometric_responses\")\n",
        "        shg = unconventional_inputs.get(\"shg_membership_info\")\n",
        "\n",
        "        # helper safe checks\n",
        "        def is_available(x):\n",
        "            return x != \"NA\" and x is not None\n",
        "\n",
        "        # simple call stats\n",
        "        if is_available(calls):\n",
        "            # compute avg daily calls in last 30 days\n",
        "            from datetime import datetime, timedelta\n",
        "            now = datetime.utcnow()\n",
        "            last30 = [c for c in calls if \"timestamp\" in c and datetime.fromisoformat(c[\"timestamp\"].replace(\"Z\",\"\")) >= (now - timedelta(days=30))]\n",
        "            profile[\"mobile_metadata\"][\"avg_daily_calls\"] = round(len(last30)/30.0,4)\n",
        "            contacts = set([c.get(\"contact_id\") for c in last30 if c.get(\"contact_id\")])\n",
        "            profile[\"mobile_metadata\"][\"unique_contacts_30d\"] = len(contacts)\n",
        "            # days inactive\n",
        "            days_with_activity = set([datetime.fromisoformat(c[\"timestamp\"].replace(\"Z\",\"\")).date() for c in last30])\n",
        "            profile[\"mobile_metadata\"][\"days_inactive_last_30\"] = max(0, 30 - len(days_with_activity))\n",
        "        else:\n",
        "            profile[\"mobile_metadata\"][\"avg_daily_calls\"] = \"NA\"\n",
        "            profile[\"mobile_metadata\"][\"unique_contacts_30d\"] = \"NA\"\n",
        "            profile[\"mobile_metadata\"][\"days_inactive_last_30\"] = \"NA\"\n",
        "\n",
        "        # airtime\n",
        "        if is_available(topups):\n",
        "            from datetime import datetime\n",
        "            now = datetime.utcnow()\n",
        "            topups_30 = [t for t in topups if \"timestamp\" in t and datetime.fromisoformat(t[\"timestamp\"].replace(\"Z\",\"\")) >= (now - timedelta(days=30))]\n",
        "            profile[\"mobile_metadata\"][\"airtime_topup_frequency\"] = round(len(topups_30)/30.0,4)\n",
        "            profile[\"mobile_metadata\"][\"avg_topup_amount\"] = round(sum([t.get(\"amount\",0) for t in topups_30])/len(topups_30),2) if len(topups_30)>0 else 0.0\n",
        "        else:\n",
        "            profile[\"mobile_metadata\"][\"airtime_topup_frequency\"] = \"NA\"\n",
        "            profile[\"mobile_metadata\"][\"avg_topup_amount\"] = \"NA\"\n",
        "\n",
        "        # wallet & savings -> financial_behavior\n",
        "        if is_available(savings):\n",
        "            profile[\"financial_behavior\"][\"savings_frequency\"] = round(len(savings)/3.0,4)  # per month proxy\n",
        "            amounts = [s.get(\"amount\",0) for s in savings]\n",
        "            import statistics as stats\n",
        "            profile[\"financial_behavior\"][\"savings_amount_variance\"] = round(stats.pvariance(amounts) if len(amounts)>1 else 0.0,4)\n",
        "        else:\n",
        "            profile[\"financial_behavior\"][\"savings_frequency\"] = \"NA\"\n",
        "            profile[\"financial_behavior\"][\"savings_amount_variance\"] = \"NA\"\n",
        "\n",
        "        if is_available(wallet_ts):\n",
        "            # wallet lows last 90d threshold at 100 currency units\n",
        "            lows = 0\n",
        "            from datetime import datetime\n",
        "            now = datetime.utcnow()\n",
        "            for w in wallet_ts:\n",
        "                try:\n",
        "                    d = datetime.fromisoformat(w.get(\"date\"))\n",
        "                    if d >= (now - timedelta(days=90)) and w.get(\"balance\",0) < 100:\n",
        "                        lows += 1\n",
        "                except:\n",
        "                    pass\n",
        "            profile[\"financial_behavior\"][\"wallet_balance_lows_last_90d\"] = lows\n",
        "        else:\n",
        "            profile[\"financial_behavior\"][\"wallet_balance_lows_last_90d\"] = \"NA\"\n",
        "\n",
        "        # psychometrics mapping (normalize if Likert 1-5)\n",
        "        if is_available(psych) and isinstance(psych, dict):\n",
        "            # map a few common questions if present; otherwise compute mean\n",
        "            vals = [v for v in psych.values() if isinstance(v,(int,float))]\n",
        "            if vals:\n",
        "                # naive \"conscientiousness\" proxy = mean normalized\n",
        "                mean = sum(vals)/len(vals)\n",
        "                profile[\"psychometrics\"][\"conscientiousness_score\"] = round((mean-1)/4.0,4)\n",
        "                # keep full responses for audit\n",
        "                profile[\"_raw_unconventional\"][\"psychometric_responses_full\"] = psych\n",
        "            else:\n",
        "                profile[\"psychometrics\"][\"conscientiousness_score\"] = \"NA\"\n",
        "        else:\n",
        "            profile[\"psychometrics\"][\"conscientiousness_score\"] = \"NA\"\n",
        "\n",
        "        # shg info\n",
        "        if is_available(shg) and isinstance(shg, dict):\n",
        "            profile[\"social_network\"][\"shg_membership\"] = bool(shg.get(\"shg_membership\", False))\n",
        "            profile[\"social_network\"][\"peer_monitoring_strength\"] = shg.get(\"peer_monitoring_strength\", \"NA\")\n",
        "            profile[\"social_network\"][\"consistency_in_group_meetings\"] = shg.get(\"consistency_in_group_meetings\", \"NA\")\n",
        "        else:\n",
        "            profile[\"social_network\"][\"shg_membership\"] = \"NA\"\n",
        "            profile[\"social_network\"][\"peer_monitoring_strength\"] = \"NA\"\n",
        "            profile[\"social_network\"][\"consistency_in_group_meetings\"] = \"NA\"\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"Warning: error while aggregating unconventional inputs:\", e)\n",
        "\n",
        "    return profile\n",
        "\n",
        "def interactive_run_and_save(user_id: str = None):\n",
        "    \"\"\"\n",
        "    Interactive flow:\n",
        "    - collect demographics minimal fields\n",
        "    - collect unconventional inputs interactively\n",
        "    - build profile\n",
        "    - save to memory\n",
        "    - call rag_qna_structured and show/save output\n",
        "    \"\"\"\n",
        "    if user_id is None:\n",
        "        user_id = input(\"Enter a user_id (e.g., user_001) > \").strip()\n",
        "    if user_id == \"\":\n",
        "        user_id = \"user_\"+datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
        "\n",
        "    print(\"\\nEnter basic demographics (press Enter to skip / NA):\")\n",
        "    age_raw = input(\"Age (int) > \").strip()\n",
        "    try:\n",
        "        age = int(age_raw) if age_raw and age_raw.upper()!=\"NA\" else None\n",
        "    except:\n",
        "        age = None\n",
        "    occupation = input(\"Occupation > \").strip() or None\n",
        "    income_raw = input(\"Monthly income (numeric) > \").strip()\n",
        "    try:\n",
        "        monthly_income = float(income_raw) if income_raw and income_raw.upper()!=\"NA\" else None\n",
        "    except:\n",
        "        monthly_income = None\n",
        "\n",
        "    demographics = {\n",
        "        \"age\": age,\n",
        "        \"occupation\": occupation,\n",
        "        \"monthly_income\": monthly_income\n",
        "    }\n",
        "\n",
        "    print(\"\\nNow provide unconventional data (you can paste full JSON arrays/objects). Type NA to skip any.\")\n",
        "    unconventional_inputs = collect_unconventional_inputs_interactive()\n",
        "\n",
        "    # Build profile\n",
        "    profile = build_profile_from_inputs(user_id, demographics, unconventional_inputs)\n",
        "\n",
        "    # Save to memory (profile)\n",
        "    try:\n",
        "        add_to_memory(user_id, profile=profile, utterance=None)\n",
        "        print(f\"\\nSaved profile to memory for user_id={user_id}\")\n",
        "    except Exception as e:\n",
        "        print(\"Warning: could not save to memory (missing add_to_memory). Exception:\", e)\n",
        "\n",
        "    # Run RAG structured Q&A\n",
        "    print(\"\\nNow enter the user's question (e.g., 'Am I eligible for a ₹50,000 loan?'):\")\n",
        "    user_question = input(\"Question > \").strip()\n",
        "    if user_question == \"\":\n",
        "        user_question = \"Am I eligible for a microloan of 50,000 INR?\"\n",
        "\n",
        "    # Ensure rag_qna_structured exists\n",
        "    if \"rag_qna_structured\" not in globals():\n",
        "        raise RuntimeError(\"rag_qna_structured is not defined in this notebook. Run the earlier RAG cell that provides it before executing this cell.\")\n",
        "\n",
        "    print(\"\\nRunning RAG-based decision. Please wait...\")\n",
        "    result = rag_qna_structured(user_question, user_id=user_id, profile=profile, k=6)\n",
        "\n",
        "    # Save output\n",
        "    out_path = OUT_DIR / f\"last_output_{user_id}.json\"\n",
        "    with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(result, f, indent=2)\n",
        "    print(f\"\\nStructured output saved to: {out_path}\\n\")\n",
        "    print(\"---- START OF OUTPUT ----\")\n",
        "    print(json.dumps(result, indent=2))\n",
        "    print(\"---- END OF OUTPUT ----\")\n",
        "    return result\n",
        "\n",
        "# If running as script/cell, call interactive_run_and_save()\n",
        "print(\"Run interactive_run_and_save() to start interactive input collection and RAG decision.\")\n",
        "# Example: uncomment to run immediately:\n",
        "# interactive_run_and_save(\"demo_user_001\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "feoocBVHfr1I",
        "outputId": "3bd67f68-8e58-4cfd-8078-57c84f5597b1"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run interactive_run_and_save() to start interactive input collection and RAG decision.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "interactive_run_and_save()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JI6oynGNhOLQ",
        "outputId": "03ae2614-8f52-4ef4-f3e6-55363e21f3f5"
      },
      "execution_count": 16,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter a user_id (e.g., user_001) > user_1\n",
            "\n",
            "Enter basic demographics (press Enter to skip / NA):\n",
            "Age (int) > 45\n",
            "Occupation > street vendor\n",
            "Monthly income (numeric) > 20000\n",
            "\n",
            "Now provide unconventional data (you can paste full JSON arrays/objects). Type NA to skip any.\n",
            "COLLECTING UNCONVENTIONAL DATA — type NA if not available.\n",
            "(You can paste JSON arrays/objects directly when prompted.)\n",
            "\n",
            "Enter mobile_call_logs_30d as JSON array of objects, or type NA (without quotes) if unavailable.\n",
            "Examples:\n",
            "[{\"timestamp\":\"2025-11-01T08:12:00Z\",\"duration_sec\":120,\"contact_id\":\"c1\",\"direction\":\"out\"}, ...]\n",
            "mobile_call_logs_30d > NA\n",
            "\n",
            "Enter airtime_topups_30d as JSON array of objects, or type NA (without quotes) if unavailable.\n",
            "Examples:\n",
            "[{\"timestamp\":\"2025-11-05T12:00:00Z\",\"amount\":50.0}, ...]\n",
            "airtime_topups_30d > NA\n",
            "\n",
            "Enter psychometric_responses as JSON object (e.g., psychometric responses), or NA if unavailable.\n",
            "{\"C_q1\":4,\"C_q2\":3,\"C_q3\":4,\"I_q1\":3,\"I_q2\":2}\n",
            "psychometric_responses > NA\n",
            "\n",
            "Enter savings_history_90d as JSON array of objects, or type NA (without quotes) if unavailable.\n",
            "Examples:\n",
            "[{\"timestamp\":\"2025-09-10T00:00:00Z\",\"amount\":200.0}, ...]\n",
            "savings_history_90d > NA\n",
            "\n",
            "Enter wallet_balance_timeseries_90d as JSON array of objects, or type NA (without quotes) if unavailable.\n",
            "Examples:\n",
            "[{\"date\":\"2025-08-01\",\"balance\":450.0}, ...]\n",
            "wallet_balance_timeseries_90d > NA\n",
            "\n",
            "Enter shg_membership_info as JSON object (e.g., psychometric responses), or NA if unavailable.\n",
            "{\"shg_membership\": true, \"peer_monitoring_strength\": 0.7, \"consistency_in_group_meetings\": 0.8}\n",
            "shg_membership_info > NA\n",
            "\n",
            "Enter transaction_history_180d as JSON array of objects, or type NA (without quotes) if unavailable.\n",
            "Examples:\n",
            "[{\"timestamp\":\"2025-06-01T10:00:00Z\",\"amount\":250.0,\"type\":\"sale\"}, ...]\n",
            "transaction_history_180d > NA\n",
            "\n",
            "Enter sms_patterns_30d as JSON array of objects, or type NA (without quotes) if unavailable.\n",
            "Examples:\n",
            "[{\"timestamp\":\"2025-11-01T09:00:00Z\",\"contact_id\":\"c1\",\"text_snippet\":\"paid today\"}, ...]\n",
            "sms_patterns_30d > NA\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "UnboundLocalError",
          "evalue": "cannot access local variable 'datetime' where it is not associated with a value",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1427044604.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minteractive_run_and_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-2084664408.py\u001b[0m in \u001b[0;36minteractive_run_and_save\u001b[0;34m(user_id)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m     \u001b[0;31m# Build profile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m     \u001b[0mprofile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_profile_from_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdemographics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munconventional_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[0;31m# Save to memory (profile)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2084664408.py\u001b[0m in \u001b[0;36mbuild_profile_from_inputs\u001b[0;34m(user_id, demographics, unconventional_inputs)\u001b[0m\n\u001b[1;32m    101\u001b[0m     profile = {\n\u001b[1;32m    102\u001b[0m         \u001b[0;34m\"user_id\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0muser_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;34m\"timestamp\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutcnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misoformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"Z\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m         \u001b[0;34m\"demographics\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdemographics\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;31m# mobile_metadata will be computed if raw call/sms/topup data available; otherwise mark NA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnboundLocalError\u001b[0m: cannot access local variable 'datetime' where it is not associated with a value"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MbSs6owehhKK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}